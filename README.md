# AWS_Bedrock
Generative AI example using Amazon bedrock

#Titan Models

Amazon Titan Foundation Models are pre-trained on large datasets, making them powerful, general-purpose models. Use them as is, or customize them by fine tuning the models with your own data for a particular task without annotating large volumes of data.


There are three types of Titan models, embeddings, text generation, and image generation.


There are two Titan Embeddings models. The Titan Embeddings G1 – Text model translate text inputs (words, phrases or possibly large units of text) into numerical representations (known as embeddings) that contain the semantic meaning of the text. While this LLM will not generate text, it is useful for applications like personalization and search. By comparing embeddings, the model will produce more relevant and contextual responses than word matching. The new Titan Multimodal Embeddings G1 model is used for use cases like searching image by text, by image for similarity or by a combination of text and image. It translates the input image or text into an embedding that contain the semantic meaning of both the image and text in the same semantic space.


Titan Text models are generative LLMs for tasks such as summarization, text generation (for example, creating a blog post), classification, open-ended Q&A, and information extraction. They are also trained on many different programming languages as well as rich text format like tables, JSON and csv’s among others.


Titan Image Generator G1 is a generative foundation model that generates images from natural language text. This model can also be used to edit or generate variations for an existing or a generated image.




<img width="1010" alt="image" src="https://github.com/amarjit420/AWS_Bedrock/assets/80757241/03aea32b-ed53-40f1-b13c-540a028651af">


